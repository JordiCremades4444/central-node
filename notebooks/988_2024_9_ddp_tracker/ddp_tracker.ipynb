{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDP tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "sys.path.append('c:/Users/Jordi Cremades/Documents/Repos/central-node')\n",
    "\n",
    "from src import query_engines\n",
    "\n",
    "q = query_engines.QueryEngines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_IN_ADVANCE = \"8\"\n",
    "\n",
    "params = [\n",
    "    {'name':'days_in_advance', 'value': DAYS_IN_ADVANCE},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_partners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought_products_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamic_sessions_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fct_contact_intent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_order_levels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groceries_top_partners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_descriptors_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders_gmv_variation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products_gmv_variation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_refund_incidents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pna_orders_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pna_products_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_availability_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_collections_flattened_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products_v2_daily\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retention_order_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessions_nc_rc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spm_ddp_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_address_product_stockout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pna_bot_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pna_bot_gmv_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacement_engine_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacement_engine_info_dh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users/Jordi Cremades/Documents/Repos/central-node\\src\\query_engines.py:197: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(self.tp__read_query, conn)\n"
     ]
    }
   ],
   "source": [
    "# calendar\n",
    "print('calendar')\n",
    "q.prepare_query(query_file='ddps/calendar.sql', params=params)\n",
    "df1 = q.query_run_starburst()\n",
    "\n",
    "# active_partners\n",
    "print('active_partners')\n",
    "q.prepare_query(query_file='ddps/active_partners.sql', params=params)\n",
    "df2 = q.query_run_starburst()\n",
    "\n",
    "# bought_products_v2\n",
    "print('bought_products_v2')\n",
    "q.prepare_query(query_file='ddps/bought_products_v2.sql', params=params)\n",
    "df3 = q.query_run_starburst()\n",
    "\n",
    "# dynamic_sessions_v1\n",
    "print('dynamic_sessions_v1')\n",
    "q.prepare_query(query_file='ddps/dynamic_sessions_v1.sql', params=params)\n",
    "df4 = q.query_run_starburst()\n",
    "\n",
    "# fct_contact_intent\n",
    "print('fct_contact_intent')\n",
    "q.prepare_query(query_file='ddps/fct_contact_intent.sql', params=params)\n",
    "df5 = q.query_run_starburst()\n",
    "\n",
    "# first_order_levels\n",
    "print('first_order_levels')\n",
    "q.prepare_query(query_file='ddps/first_order_levels.sql', params=params)\n",
    "df6 = q.query_run_starburst()\n",
    "\n",
    "# groceries_top_partners\n",
    "print('groceries_top_partners')\n",
    "q.prepare_query(query_file='ddps/groceries_top_partners.sql', params=params)\n",
    "df7 = q.query_run_starburst()\n",
    "\n",
    "# order_descriptors_v2\n",
    "print('order_descriptors_v2')\n",
    "q.prepare_query(query_file='ddps/order_descriptors_v2.sql', params=params)\n",
    "df8 = q.query_run_starburst()\n",
    "\n",
    "# orders_gmv_variation\n",
    "print('orders_gmv_variation')\n",
    "q.prepare_query(query_file='ddps/orders_gmv_variation.sql', params=params)\n",
    "df9 = q.query_run_starburst()\n",
    "\n",
    "# products_gmv_variation\n",
    "print('products_gmv_variation')\n",
    "q.prepare_query(query_file='ddps/products_gmv_variation.sql', params=params)\n",
    "df10 = q.query_run_starburst()\n",
    "\n",
    "# order_refund_incidents\n",
    "print('order_refund_incidents')\n",
    "q.prepare_query(query_file='ddps/order_refund_incidents.sql', params=params)\n",
    "df11 = q.query_run_starburst()\n",
    "\n",
    "# pna_orders_info\n",
    "print('pna_orders_info')\n",
    "q.prepare_query(query_file='ddps/pna_orders_info.sql', params=params)\n",
    "df12 = q.query_run_starburst()\n",
    "\n",
    "# pna_products_info\n",
    "print('pna_products_info')\n",
    "q.prepare_query(query_file='ddps/pna_products_info.sql', params=params)\n",
    "df13 = q.query_run_starburst()\n",
    "\n",
    "# product_availability_v2\n",
    "print('product_availability_v2')\n",
    "q.prepare_query(query_file='ddps/product_availability_v2.sql', params=params)\n",
    "df14 = q.query_run_starburst()\n",
    "\n",
    "# product_collections_flattened_v2\n",
    "print('product_collections_flattened_v2')\n",
    "q.prepare_query(query_file='ddps/product_collections_flattened_v2.sql', params=params)\n",
    "df15 = q.query_run_starburst()\n",
    "\n",
    "# products_v2_daily\n",
    "print('products_v2_daily')\n",
    "q.prepare_query(query_file='ddps/products_v2_daily.sql', params=params)\n",
    "df16 = q.query_run_starburst()\n",
    "\n",
    "# retention_order_info\n",
    "print('retention_order_info')\n",
    "q.prepare_query(query_file='ddps/retention_order_info.sql', params=params)\n",
    "df17 = q.query_run_starburst()\n",
    "\n",
    "# sessions_nc_rc\n",
    "print('sessions_nc_rc')\n",
    "q.prepare_query(query_file='ddps/sessions_nc_rc.sql', params=params)\n",
    "df18 = q.query_run_starburst()\n",
    "\n",
    "# spm_ddp_info\n",
    "print('spm_ddp_info')\n",
    "q.prepare_query(query_file='ddps/spm_ddp_info.sql', params=params)\n",
    "df19 = q.query_run_starburst()\n",
    "\n",
    "# store_address_product_stockout\n",
    "print('store_address_product_stockout')\n",
    "q.prepare_query(query_file='ddps/store_address_product_stockout.sql', params=params)\n",
    "df20 = q.query_run_starburst()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# pna_bot_info\n",
    "print('pna_bot_info')\n",
    "q.prepare_query(query_file='ddps/pna_bot_info.sql', params=params)\n",
    "df_1 = q.query_run_starburst()\n",
    "\n",
    "# pna_bot_gmv_info\n",
    "print('pna_bot_gmv_info')\n",
    "q.prepare_query(query_file='ddps/pna_bot_gmv_info.sql', params=params)\n",
    "df_2 = q.query_run_starburst()\n",
    "\n",
    "# replacement_engine_info\n",
    "print('replacement_engine_info')\n",
    "q.prepare_query(query_file='ddps/replacement_engine_info.sql', params=params)\n",
    "df_3 = q.query_run_starburst()\n",
    "\n",
    "# replacement_engine_info_dh\n",
    "print('replacement_engine_info_dh')\n",
    "q.prepare_query(query_file='ddps/replacement_engine_info_dh.sql', params=params)\n",
    "df_4 = q.query_run_starburst()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDP_tracker_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16, df17, df18, df19, df20]\n",
    "\n",
    "merged_df = df1.copy()\n",
    "\n",
    "for df in dataframes:\n",
    "    if not df.empty:\n",
    "        merged_df = pd.merge(merged_df, df, on='p_creation_date', how='left')\n",
    "\n",
    "for col in merged_df.columns:\n",
    "    if merged_df[col].dtype == 'float64':\n",
    "        merged_df[col] = merged_df[col].fillna(0).astype(int)\n",
    "        \n",
    "pivot_table = merged_df.set_index('p_creation_date').T\n",
    "\n",
    "pivot_table.to_csv('outputs/ddp_tracker_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDP_tracker_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df_1, df_2, df_3, df_4]\n",
    "\n",
    "merged_df = pd.concat(dataframes, axis=1)\n",
    "\n",
    "merged_df.to_csv('outputs/ddp_tracker_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
